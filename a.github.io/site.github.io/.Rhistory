pval.coord = c(3, 0.05),
pval.size = 3,
surv.scale = "percent",
conf.int.style = "ribbon",
conf.int.alpha = 0.05,
xlab = "Horas",  # Eixo X rotulado como "Horas"
ylab = "Probabilidade de sobrevivência",
title = "Sobrevivência de adultos",
legend.title = "Tratamentos",
surv.median.line = "hv",
palette = c("#D0E789", "#50A34B", "#3320A2", "#8D0987", "darkorange"),
ggtheme = theme_classic(),
# Ajustar o limite do eixo X (0 a 100 horas, por exemplo)
xlim = c(0, 100))
# Ajustar o limite do eixo Y para começar de 70%
plot$plot <- plot$plot + coord_cartesian(ylim = c(0.7, 1))
# Customizar os rótulos do eixo X para horas específicas
plot$plot <- plot$plot + scale_x_continuous(breaks = c(0, 24, 48, 72, 96))
# Exibir o gráfico
plot
arenas <- read.csv("arenas_fip606.csv", header = T, stringsAsFactors = T)
# Analisar as variáveis do modelo
if(!require(dplyr)) install.packages("dplyr")
library(dplyr)
glimpse(arenas)
# Instalar e carregar pacotes necessários
if (!require(lme4)) install.packages("lme4")
library(lme4)
if (!require(glmmTMB)) install.packages("glmmTMB")
library(glmmTMB)
# Ajustar modelo misto com efeito aleatório de tempo e família binomial negativa (modelo 1)
mod1 <- glmmTMB(num ~ trat * local + (1 | tempo),
data = arenas,
family = nbinom2)
summary(mod1)
# Ajustar modelo apenas com efeitos fixos (modelo 2)
mod2 <- glmmTMB(num ~ trat * local,
data = arenas,
family = nbinom2)
summary(mod2)
# Ajustar modelo usando glmer (Poisson), incluindo tempo como efeito fixo e aleatório (modelo 3)
mod3 <- glmer(num ~ trat * local * tempo + (1 | tempo),
data = arenas,
family = poisson(link = "log"))
summary(mod3)
# Comparar os modelos usando AIC
AIC(mod1, mod2, mod3)
# Comentário interpretativo
#
# Normalidade de resíduos
if(!require(nortest)) install.packages("nortest")
library(nortest)
plot(residuals(mod1))
lillie.test(residuals(mod1)) # Não atende pressupostos
# Homocedastiticade
bartlett.test(num ~ tempo, data = arenas) # Não atende pressupostos
bartlett.test(num ~ trat, data = arenas) # Não atende pressupostos
bartlett.test(num ~ local, data = arenas) # Não atende pressupostos
# Modelo misto com binomial negativa (recomendado para dados de contagem com sobredispersão)
mod1 <- glmmTMB(num ~ trat * local * tempo + (1|tempo),
data = arenas,
family = nbinom2)
summary(mod1)
if(!require(emmeans)) install.packages("emmeans")
library(emmeans)
if(!require(multcomp)) install.packages("multcomp")
library(multcomp)
if(!require(multcompView)) install.packages("multcompView")
library(multcompView)
# Calcular as médias marginais estimadas
emm <- emmeans(mod1, pairwise ~ trat * local, adjust = "tukey")
# Obter as comparações
comparacoes <- as.data.frame(emm$contrasts)
# Criar uma matriz de p-valores
teste_posthoc <- emmeans(mod1, pairwise ~ trat | local)$contrasts %>%
summary(infer = TRUE)
# Obter as letras
letras <- cld(emmeans(mod1, ~ trat | local),
adjust = "tukey",
Letters = letters,
alpha = 0.05)
# Visualizar as letras
print(letras)
# Gráfico com as letras de significância
if(!require(ggplot2)) install.packages("ggplot2")
library(ggplot2)
# Preparação dos dados
dados_observados <- arenas %>%
group_by(trat, local) %>%
summarise(
media_num = mean(num),
sd_num = sd(num),
n = n(),
se_num = sd_num / sqrt(n)
) %>%
ungroup()
# Verificar nomes das colunas de 'letras'
letras_df <- as.data.frame(letras)
print(colnames(letras_df))
# Selecionar as colunas desejadas
colunas <- c("trat", "local", ".group")
letras_selecionadas <- letras_df[, colnames(letras_df) %in% colunas]
# Fazer o join
dados_completos <- left_join(dados_observados,
letras_selecionadas,
by = c("trat", "local"))
# Definir a paleta de cores personalizada
paleta_cores <- c(
"NT" = "#D0E789",
"C"  = "#50A34B",
"E"  = "#3320A2",
"G"  = "#8D0987",
"T"  = "darkorange"
)
# Criar o gráfico com a paleta de cores
ggplot(dados_completos, aes(x = trat, y = media_num, fill = trat)) +
geom_col(position = position_dodge()) +
geom_errorbar(aes(ymin = media_num - se_num, ymax = media_num + se_num),
width = 0.2, position = position_dodge(0.9)) +
geom_text(aes(label = .group, y = media_num + se_num + 0.5),
position = position_dodge(0.9), vjust = 0, size = 3.5) +
facet_wrap(~ local, scales = "free_y") +
labs(x = "Tratamento",
y = "Número médio de insetos observados",
fill = "Tratamentos") +
theme_minimal() +
theme(legend.position = "top") +
scale_fill_manual(values = paleta_cores) +  # Aplique a paleta de cores aqui
scale_y_continuous(limits = c(0, 14))
rep <- read.csv("indice_fip606.csv", header = T, stringsAsFactors = T)
# Analisar as variáveis do modelo
if(!require(dplyr)) install.packages("dplyr")
library(dplyr)
glimpse(rep)
# Substituindo vírgulas por pontos em rep$indice
rep$indice <- as.numeric(gsub(",", ".", rep$indice))
glimpse(rep)
if(!require(ggplot2)) install.packages("ggplot2")
library(ggplot2)
# Definir a paleta de cores personalizada para os tratamentos
paleta_cores <- c(
"NT" = "#D0E789",
"C"  = "#50A34B",
"E"  = "#3320A2",
"G"  = "#8D0987",
"T"  = "darkorange"
)
# Criar o gráfico com a paleta de cores
ggplot(rep, aes(x = tempo, y = indice, color = trat)) +
geom_jitter(alpha = 0.6) +
geom_smooth(method = "lm", se = FALSE) + # Linhas de regressão para cada tratamento
labs(title = "Índice por Tempo e Tratamento",
x = "Tempo",
y = "Índice",
color = "Tratamento") +
theme_minimal() +
scale_color_manual(values = paleta_cores)  # Aplique a paleta de cores personalizada
if(!require(ggplot2)) install.packages("ggplot2")
library(ggplot2)
# Definir a paleta de cores personalizada para os tratamentos
paleta_cores <- c(
"NT" = "#D0E789",
"C"  = "#50A34B",
"E"  = "#3320A2",
"G"  = "#8D0987",
"T"  = "darkorange"
)
# Criar o gráfico com a paleta de cores
ggplot(rep, aes(x = tempo, y = indice, color = trat)) +
geom_jitter(alpha = 0.6) +
geom_smooth(method = "lm", se = FALSE) + # Linhas de regressão para cada tratamento
labs(title = "Índice por Tempo e Tratamento",
x = "Tempo",
y = "Índice",
color = "Tratamento") +
theme_minimal() +
scale_color_manual(values = paleta_cores)  # Aplique a paleta de cores personalizada
# Testando modelo com interação
mod <- lm(indice ~ tempo + trat + tempo * trat, data = rep)
summary(mod)
# As interações não foram significativas, vamos testar o modelo sem interações
mod <- lm(indice ~ tempo + trat, data = rep)
summary(mod)
# Normalidade de resíduos
if(!require(nortest)) install.packages("nortest")
library(nortest)
plot(residuals(mod))
lillie.test(residuals(mod)) # Não atende pressupostos
# Homocedastiticade
bartlett.test(indice ~ tempo, data = rep) # Atende pressupostos
bartlett.test(indice ~ trat, data = rep) # Não atende pressupostos
# Teste com glm familia beta (betareg)
# Carregar pacotes
if(!require(betareg)) install.packages("betareg")
library(betareg)
if(!require(car)) install.packages("car")
library(car)
# Dados separados para adaptação
rep_beta <- rep
# Garantir que o índice esteja estritamente entre -100 e 100
rep_beta$indice <- pmax(-99.99, pmin(99.99, rep_beta$indice))
# Reescalar a variável resposta 'indice' para o intervalo (0, 1)
# Essa variável aparece no intervalo de -100 a 100, porém, a análise de Regressão Beta necessita de valores no espaço de 0 a 1.
# Então, para a análise, utilizaremos uma adaptação, onde faremos a proporção dos valores de -100 a 100 para valores representados entre 0 e 1.
epsilon <- 0.0001 # Um valor pequeno para evitar 0 e 1 exatos
rep_beta <- rep_beta %>%
mutate(indice_rescalado = (indice - (-100)) / (100 - (-100))) %>% # Mapeia para [0,1]
mutate(indice_rescalado = (indice_rescalado * (1 - 2 * epsilon)) + epsilon)
print(summary(rep_beta$indice_rescalado))
print(head(rep_beta))
# Ajustar o Modelo Beta Regression sem interação
# O 'link = "logit"' é o padrão e geralmente a melhor escolha para dados Beta.
modbeta <- betareg(indice_rescalado ~ tempo + trat, data = rep_beta)
summary(modbeta)
Anova(modbeta, type = 2)
if(!require(multcomp)) install.packages("multcomp")
library(multcomp)
if(!require(emmeans)) install.packages("emmeans")
library(emmeans)
# Calcular as médias marginais estimadas para cada tratamento, ajustadas em relação ao tempo
em_means_trat <- emmeans(modbeta, ~ trat, type = "response")
print(em_means_trat)
# Realizar as comparações post-hoc com ajuste de Tukey
pairs(em_means_trat, adjust = "tukey")
cld_result <- cld(em_means_trat, adjust = "tukey", Letters = LETTERS)
message("\n--- Resultado do CLD (letras de agrupamento) ---")
print(cld_result)
cld_df <- as.data.frame(cld_result) %>%
dplyr::select(trat, .group) %>%
rename(label = .group)
pos_x_letras <- max(rep_beta$tempo)
# Criar um dataframe de nova_data para prever o Y no tempo máximo para cada 'trat'
df_para_prever_letras <- data.frame(
trat = levels(rep_beta$trat),
tempo = pos_x_letras # Usa o tempo máximo para todas as previsões
)
# Fazer a previsão na escala reescalada e depois transformar
previsoes_y_letras <- predict(modbeta, newdata = df_para_prever_letras, type = "response")
# Transformar previsões para a escala ORIGINAL (-100 a 100)
previsoes_y_letras_original <- ((previsoes_y_letras - epsilon) / (1 - 2 * epsilon)) * 200 - 100
# Adicionar as previsões ao dataframe
df_para_prever_letras$y_pos_original <- previsoes_y_letras_original
# Ajustar corretamente a altura das letras
df_para_prever_letras$y_pos_original[1] <- -40
df_para_prever_letras$y_pos_original[2] <- 1
df_para_prever_letras$y_pos_original[3] <- 11.20000
df_para_prever_letras$y_pos_original[4] <- 20
df_para_prever_letras$y_pos_original[5] <- -30
# Unir as letras CLD com as posições Y previstas
plot_labels_cld <- left_join(df_para_prever_letras, cld_df, by = "trat") %>%
mutate(y_pos_final = y_pos_original + 5)
# Definir a paleta de cores personalizada para os tratamentos
paleta_cores <- c(
"NT" = "#D0E789",
"C"  = "#50A34B",
"E"  = "#3320A2",
"G"  = "#8D0987",
"T"  = "darkorange"
)
# Criar o gráfico com a paleta de cores personalizada
ggplot(rep_beta, aes(x = tempo, y = indice, colour = trat)) +
geom_jitter(width = 0.1, height = 0.5, alpha = 0.6) +
geom_smooth(formula = y ~ x, se = FALSE, size = 0.8) +
geom_text(data = plot_labels_cld,
aes(x = tempo, y = y_pos_final, label = label, color = trat),
size = 3,
hjust = -0.1,  # Ajuste para a letra ficar um pouco à direita do final da linha
vjust = 0.5,  # Ajusta o alinhamento vertical da letra
show.legend = FALSE) +  # Não mostrar as letras na legenda
labs(
title = "Índice Original por Tempo e Tratamento com CLD",
x = "Tempo",
y = "Índice Original (-100 a 100)",
color = "Tratamento"
) +
scale_y_continuous(limits = c(-100, 100 + 10)) +
scale_x_continuous(limits = c(min(rep_beta$tempo), max(rep_beta$tempo) + 1)) +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5)) +
scale_color_manual(values = paleta_cores)  # Aplique a paleta de cores personalizada
arenas <- read.csv("arenas_fip606.csv", header = T, stringsAsFactors = T)
# Analisar as variáveis do modelo
if(!require(dplyr)) install.packages("dplyr")
library(dplyr)
glimpse(arenas)
# Ajustar variáveis no dataframe para facilitar análises futuras
arenas$local <- as.character(arenas$local)
arenas$local <- ifelse(arenas$local == -1, "neg_1", arenas$local)
arenas$local <- ifelse(arenas$local == "-0,5", "neg_05", arenas$local)
# Criando novos dataframes por tratamento
datant <- arenas %>%
filter(trat == "NT")
datae <- arenas %>%
filter(trat == "E")
datag <- arenas %>%
filter(trat == "G")
datac <- arenas %>%
filter(trat == "C")
datat <- arenas %>%
filter(trat == "T")
# Criando novos dataframes por tratamento
datant <- arenas %>%
filter(trat == "NT")
datae <- arenas %>%
filter(trat == "E")
datag <- arenas %>%
filter(trat == "G")
datac <- arenas %>%
filter(trat == "C")
datat <- arenas %>%
filter(trat == "T")
if(!require(nortest)) install.packages("nortest")
library(nortest)
datant %>%
group_by(trat) %>%
summarise(
Estatística_Shapiro = shapiro.test(num)$statistic,
p_valor = shapiro.test(num)$p.value
)
datae %>%
group_by(trat) %>%
summarise(
Estatística_Shapiro = shapiro.test(num)$statistic,
p_valor = shapiro.test(num)$p.value
)
datag %>%
group_by(trat) %>%
summarise(
Estatística_Shapiro = shapiro.test(num)$statistic,
p_valor = shapiro.test(num)$p.value
)
datac %>%
group_by(trat) %>%
summarise(
Estatística_Shapiro = shapiro.test(num)$statistic,
p_valor = shapiro.test(num)$p.value
)
datat %>%
group_by(trat) %>%
summarise(
Estatística_Shapiro = shapiro.test(num)$statistic,
p_valor = shapiro.test(num)$p.value
)
bartlett.test(num ~ local, data = datant)
bartlett.test(num ~ local, data = datae)
bartlett.test(num ~ local, data = datag)
bartlett.test(num ~ local, data = datac)
bartlett.test(num ~ local, data = datat)
if(!require(rstatix)) install.packages("rstatix")
library(rstatix)
dunn_nt <- dunn_test(num ~ local, data = datant, p.adjust.method = "bonferroni")
if(!require(multcompView)) install.packages("multcompView")
library(multcompView)
# Criar matriz de comparações para o multcompView
p_nt <- setNames(dunn_nt$p.adj,
paste(dunn_nt$group1, dunn_nt$group2, sep = "-"))
# Obter letras de significância
letter_nt <- multcompLetters(p_nt)
# Preparar dados para o gráfico
letras_plot_nt <- data.frame(
local = names(letter_nt$Letters),
letra = letter_nt$Letters,
y_pos = max(datant$num) * 1.1)
# Definir a ordem desejada das variáveis no eixo x
ordem_desejada <- c("neg_1", "neg_05", "0", "0,5", "1")
# Converter a variável 'local' em fator com a ordem correta
datant <- datant %>%
mutate(local = factor(local,
levels = c("neg_1", "neg_05", "0", "0,5", "1"),
labels = ordem_desejada))
# Atualizar também o dataframe letras_plot
if(exists("letras_plot_nt")) {
letras_plot_nt <- letras_plot_nt %>%
mutate(local = factor(local,
levels = c("neg_1", "neg_05", "0", "0,5", "1"),
labels = ordem_desejada))
}
# Modificar os níveis do fator nos dados
datant <- datant %>%
mutate(local = factor(local,
levels = c("neg_1", "neg_05", "0", "0,5", "1"),
labels = c("-1", "-0.5", "0", "0.5", "1")))
# Atualizar o dataframe letras_plot
letras_plot_nt <- letras_plot_nt %>%
mutate(local = factor(local,
levels = c("neg_1", "neg_05", "0", "0,5", "1"),
labels = c("-1", "-0.5", "0", "0.5", "1")))
modnt <- kruskal.test(num ~ local, data = datant)
print(modnt)
mode <- kruskal.test(num ~ local, data = datae)
print(mode)
modg <- kruskal.test(num ~ local, data = datag)
print(modg)
modc <- kruskal.test(num ~ local, data = datac)
print(modc)
modt <- kruskal.test(num ~ local, data = datat)
print(modt)
if(!require(nortest)) install.packages("nortest")
library(nortest)
datant %>%
group_by(trat) %>%
summarise(
Estatística_Shapiro = shapiro.test(num)$statistic,
p_valor = shapiro.test(num)$p.value
)
datae %>%
group_by(trat) %>%
summarise(
Estatística_Shapiro = shapiro.test(num)$statistic,
p_valor = shapiro.test(num)$p.value
)
datag %>%
group_by(trat) %>%
summarise(
Estatística_Shapiro = shapiro.test(num)$statistic,
p_valor = shapiro.test(num)$p.value
)
datac %>%
group_by(trat) %>%
summarise(
Estatística_Shapiro = shapiro.test(num)$statistic,
p_valor = shapiro.test(num)$p.value
)
datat %>%
group_by(trat) %>%
summarise(
Estatística_Shapiro = shapiro.test(num)$statistic,
p_valor = shapiro.test(num)$p.value
)
bartlett.test(num ~ local, data = datant)
bartlett.test(num ~ local, data = datae)
bartlett.test(num ~ local, data = datag)
bartlett.test(num ~ local, data = datac)
bartlett.test(num ~ local, data = datat)
if(!require(rstatix)) install.packages("rstatix")
library(rstatix)
dunn_nt <- dunn_test(num ~ local, data = datant, p.adjust.method = "bonferroni")
# Criando novos dataframes por tratamento
datant <- arenas %>%
filter(trat == "NT")
datae <- arenas %>%
filter(trat == "E")
datag <- arenas %>%
filter(trat == "G")
datac <- arenas %>%
filter(trat == "C")
datat <- arenas %>%
filter(trat == "T")
if(!require(nortest)) install.packages("nortest")
library(nortest)
datant %>%
group_by(trat) %>%
summarise(
Estatística_Shapiro = shapiro.test(num)$statistic,
p_valor = shapiro.test(num)$p.value
)
datae %>%
group_by(trat) %>%
summarise(
Estatística_Shapiro = shapiro.test(num)$statistic,
p_valor = shapiro.test(num)$p.value
)
datag %>%
group_by(trat) %>%
summarise(
Estatística_Shapiro = shapiro.test(num)$statistic,
p_valor = shapiro.test(num)$p.value
)
datac %>%
group_by(trat) %>%
summarise(
Estatística_Shapiro = shapiro.test(num)$statistic,
p_valor = shapiro.test(num)$p.value
)
datat %>%
group_by(trat) %>%
summarise(
Estatística_Shapiro = shapiro.test(num)$statistic,
p_valor = shapiro.test(num)$p.value
)
# Função para calcular o Índice de Repelência (IR)
calcular_IR <- function(N_cont, N_trat) {
IR <- ((N_cont - N_trat) / N_cont) * 100
return(IR)
}
# Exemplo de uso:
N_cont <- 100  # Número de insetos na área de controle
N_trat <- 60   # Número de insetos na área tratada
# Calculando o índice de repelência
IR <- calcular_IR(N_cont, N_trat)
print(paste("O Índice de Repelência (IR) é:", IR))
# Interpretação:
if(IR == 0) {
print("Não há repelência, ou seja, o número de insetos nas áreas tratadas é igual ao das áreas de controle.")
} else if(IR > 0) {
print("O tratamento tem algum grau de repelência, pois o número de insetos na área tratada é menor que na área de controle.")
} else {
print("O tratamento pode ter um efeito atraente, ou seja, há mais insetos nas áreas tratadas do que nas áreas de controle.")
}
# Função para calcular o Índice de Repelência (IR)
calcular_IR <- function(N_cont, N_trat) {
# A fórmula do Índice de Repelência é (N_cont - N_trat) / N_cont * 100
IR <- ((N_cont - N_trat) / N_cont) * 100
return(IR)
}
rmarkdown::render("seuarquivo.Rmd")
cd "C:/Users/josie/OneDrive/Documentos/GitHub/projetofip/a.github.io/site.github.io"
install.packages("quarto")
cd "C:/Users/josie/OneDrive/Documentos/GitHub/projetofip/a.github.io/site.github.io"
quarto render index.qmd --to html
quarto render index.qmd -- to html
"quarto render" index.qmd -- to html
